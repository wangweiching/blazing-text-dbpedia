{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9adeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/ec2-user/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4d294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from kaggle) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from kaggle) (2.26.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from kaggle) (4.62.3)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-7.0.0-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from kaggle) (1.26.8)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->kaggle) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests->kaggle) (3.1)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=39e6b953c00d42a6f56e97ebf2a690860a4fade2331d88827371f1a13c8adba9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-7.0.0 text-unidecode-1.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "802439be",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf67f855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/ec2-user/.kaggle/kaggle.json'\n",
      "ford-sentence-classifiaction-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d gaveshjain/ford-sentence-classifiaction-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dec3f243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ford-sentence-classifiaction-dataset.zip\n",
      "  inflating: sample_submission.csv   \n",
      "  inflating: test_data.csv           \n",
      "  inflating: train_data.csv          \n"
     ]
    }
   ],
   "source": [
    "!unzip ford-sentence-classifiaction-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9535ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcca324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ford-sentence-classifiaction-dataset/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aca28eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('ford-sentence-classifiaction-dataset/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f231eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('ford-sentence-classifiaction-dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09b63af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59002 entries, 0 to 60114\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    59002 non-null  int64 \n",
      " 1   Sentence_id   59002 non-null  object\n",
      " 2   New_Sentence  59002 non-null  object\n",
      " 3   Type          59002 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eed5f1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>New_Sentence</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GERRES15609</td>\n",
       "      <td>author and or review architecture design and o...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PHERES15784</td>\n",
       "      <td>should be able to develop custom dynamic shape...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GERREQ10457</td>\n",
       "      <td>experience in working crosslly with a larger e...</td>\n",
       "      <td>Requirement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>GERSKL27235</td>\n",
       "      <td>previous business experience including but not...</td>\n",
       "      <td>Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>HONSSK18415</td>\n",
       "      <td>delivering fast and right the first time</td>\n",
       "      <td>SoftSkill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Sentence_id                                       New_Sentence  \\\n",
       "0           0  GERRES15609  author and or review architecture design and o...   \n",
       "1           1  PHERES15784  should be able to develop custom dynamic shape...   \n",
       "2           2  GERREQ10457  experience in working crosslly with a larger e...   \n",
       "3           3  GERSKL27235  previous business experience including but not...   \n",
       "4           4  HONSSK18415           delivering fast and right the first time   \n",
       "\n",
       "             Type  \n",
       "0  Responsibility  \n",
       "1  Responsibility  \n",
       "2     Requirement  \n",
       "3           Skill  \n",
       "4       SoftSkill  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a6055d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Sentence_id                                                                                                                                                                 New_Sentence            Type\n",
      "0           0  GERRES15609  author and or review architecture design and other technical documents ensuring high quality deliverables and systems development across tech stacks and applications teams  Responsibility\n",
      "1           1  PHERES15784                                                                        should be able to develop custom dynamic shape object script and validation and testing with database  Responsibility\n",
      "2           2  GERREQ10457                                                                      experience in working crosslly with a larger engineering organization and multiple sites highly desired     Requirement\n",
      "3           3  GERSKL27235                                previous business experience including but not limited to business management engineering sales operations finance contracts customer support           Skill\n",
      "4           4  HONSSK18415                                                                                                                                     delivering fast and right the first time       SoftSkill\n"
     ]
    }
   ],
   "source": [
    "print(df.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e4be03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Sentence_id                                                                                                                                                                                                                           New_Sentence  predict_prob          target            Type\n",
      "0           0  UAERES16346             Collaborate across all of DB&T practices and offerings in AI, Data, IoT  and Cloud platforms to ensure we grow share in world class digital innovation, mobile/web applications helping clients reinvent their businesses.      0.006665  Responsibility  Responsibility\n",
      "1           1  COGREQ15586                                                                                                                                                                        Strong  technology expertise in Identity and Access Management.      0.176393     Requirement     Requirement\n",
      "2           2  UAEREQ12722                                                                                                                                                                                           Strong knowledge on Service  Virtualization.      0.049072     Requirement     Requirement\n",
      "3           3  COGSKL29155  Architect scalable data processing and analytics solutions, including technical feasibility for Big Data storage, processing, and consumption e.g., development  of enterprise Data Lake strategy, and heterogeneous data management.      0.228694  Responsibility  Responsibility\n",
      "4           4  PHERES12551                                                                               Map client organization, build outstanding relationships with new business units,  and build a sales strategy for developing new business opportunities.      0.003977  Responsibility  Responsibility\n"
     ]
    }
   ],
   "source": [
    "print(df_test.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c39c89f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15029 entries, 0 to 15028\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Unnamed: 0    15029 non-null  int64 \n",
      " 1   Sentence_id   15029 non-null  object\n",
      " 2   New_Sentence  14748 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 352.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e4c04f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Collaborate across all of DB&T practices and o...\n",
       "1    Strong  technology expertise in Identity and A...\n",
       "2         Strong knowledge on Service  Virtualization.\n",
       "3    Architect scalable data processing and analyti...\n",
       "4    Map client organization, build outstanding rel...\n",
       "Name: New_Sentence, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['New_Sentence'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea723b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54015dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#data preprocessing by regualar expression \n",
    "def dataPreprocessing(text):\n",
    "    text=re.sub(r'[^\\w\\s\\t\\']',' ',text)\n",
    "    text=re.sub(r' +',' ',text)\n",
    "    text = text.replace(r'/',' ')\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc14f143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "x=[]\n",
    "def datacleaning(New_Sentence):\n",
    "    remove_punctuation=[char for char in New_Sentence if char not in string.punctuation]\n",
    "\n",
    "    remove_punctuation=''.join(remove_punctuation)\n",
    "    \n",
    "    return [word for word in remove_punctuation.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "096a1083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [author, review, architecture, design, technic...\n",
      "1        [able, develop, custom, dynamic, shape, object...\n",
      "2        [experience, working, crosslly, larger, engine...\n",
      "3        [previous, business, experience, including, li...\n",
      "4                   [delivering, fast, right, first, time]\n",
      "                               ...                        \n",
      "60110    [position, utilize, program, management, skill...\n",
      "60111    [addition, individual, responsible, managing, ...\n",
      "60112                     [good, problem, solving, skills]\n",
      "60113                             [good, excel, knowledge]\n",
      "60114    [bachelors, degree, electrical, engineering, m...\n",
      "Name: New_Sentence, Length: 59002, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['New_Sentence']=df['New_Sentence'].map(dataPreprocessing)\n",
    "print(df.iloc[:,2].apply(datacleaning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30fd1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "transformer=CountVectorizer(analyzer=datacleaning).fit(df['New_Sentence'])\n",
    "#transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a94bd61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_link=transformer.transform(df['New_Sentence'])\n",
    "#print(map_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8441b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59002, 21244)\n"
     ]
    }
   ],
   "source": [
    "#most significant words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer=TfidfTransformer().fit(map_link)\n",
    "#print(tfidf_transformer)\n",
    "title_tfidf=tfidf_transformer.transform(map_link)\n",
    "#print(title_tfidf)\n",
    "print(title_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "175246f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [author, review, architecture, design, technic...\n",
      "1        [able, develop, custom, dynamic, shape, object...\n",
      "2        [experience, working, crosslly, larger, engine...\n",
      "3        [previous, business, experience, including, li...\n",
      "4                   [delivering, fast, right, first, time]\n",
      "                               ...                        \n",
      "60110    [position, utilize, program, management, skill...\n",
      "60111    [addition, individual, responsible, managing, ...\n",
      "60112                     [good, problem, solving, skills]\n",
      "60113                             [good, excel, knowledge]\n",
      "60114    [bachelors, degree, electrical, engineering, m...\n",
      "Name: New_Sentence, Length: 59002, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_test['New_Sentence']=df_test['New_Sentence'].map(dataPreprocessing)\n",
    "print(df.iloc[:,2].apply(datacleaning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a727f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14748, 21244)\n"
     ]
    }
   ],
   "source": [
    "map_link_test=transformer.transform(df_test['New_Sentence'])\n",
    "#most significant words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf__test_transformer=TfidfTransformer().fit(map_link_test)\n",
    "#print(tfidf_transformer)\n",
    "title_tfidf_test=tfidf_transformer.transform(map_link_test)\n",
    "#print(title_tfidf)\n",
    "print(title_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "638302dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import linear_model, naive_bayes, svm\n",
    "#model=svm.LinearSVC(C=1.0).fit(title_tfidf,df['New_Sentence'])\n",
    "model=MultinomialNB().fit(title_tfidf,df['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c647e405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Responsibility' 'Responsibility' 'Requirement' ... 'SoftSkill' 'Skill'\n",
      " 'Education']\n"
     ]
    }
   ],
   "source": [
    "all_predictions=model.predict(title_tfidf)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d90e01ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        New_Sentence            Type\n",
      "0  collaborate across all of db t practices and o...  Responsibility\n",
      "1  strong technology expertise in identity and ac...     Requirement\n",
      "2         strong knowledge on service virtualization           Skill\n",
      "3  architect scalable data processing and analyti...  Responsibility\n",
      "4  map client organization build outstanding rela...  Responsibility\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(title_tfidf_test)      \n",
    "y_prob = model.predict_proba(title_tfidf_test)[:,1]\n",
    "df_test['predict_prob']= y_prob\n",
    "df_test['Type']= y_predict\n",
    "final=df_test[['New_Sentence','Type']].reset_index(drop=True)\n",
    "print(final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a502a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING THE TRAINING DATASET INTO TRAIN AND TEST\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "final=df[['New_Sentence','Type']].reset_index(drop=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['New_Sentence'],df['Type'],test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d281d08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11801, 21244)\n"
     ]
    }
   ],
   "source": [
    "X_test.head()\n",
    "map_link_X_test=transformer.transform(X_test)\n",
    "#most significant words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf__test_transformer=TfidfTransformer().fit(map_link_X_test)\n",
    "#print(tfidf_transformer)\n",
    "title_tfidf_X_test=tfidf_transformer.transform(map_link_X_test)\n",
    "#print(title_tfidf)\n",
    "print(title_tfidf_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ccab9665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "     Education       0.81      0.74      0.78       875\n",
      "    Experience       0.84      0.93      0.88      1855\n",
      "   Requirement       0.61      0.63      0.62      2664\n",
      "Responsibility       0.77      0.92      0.84      3092\n",
      "         Skill       0.74      0.39      0.51      1343\n",
      "     SoftSkill       0.77      0.70      0.74      1972\n",
      "\n",
      "      accuracy                           0.75     11801\n",
      "     macro avg       0.76      0.72      0.73     11801\n",
      "  weighted avg       0.75      0.75      0.74     11801\n",
      "\n",
      "Confusion Matrix: [[ 650   36  124   48   14    3]\n",
      " [  13 1717   63   40   21    1]\n",
      " [ 130  126 1683  319  100  306]\n",
      " [   1   21  145 2853   24   48]\n",
      " [   6  128  420  214  527   48]\n",
      " [   0   14  318  232   22 1386]]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(title_tfidf_X_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('Confusion Matrix:',confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "534570a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"Sentence_id\": df_test[\"Sentence_id\"],\"New_Sentence\": df_test[\"New_Sentence\"], \"Type\": df_test[\"Type\"]})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ec9fe6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_id</th>\n",
       "      <th>New_Sentence</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UAERES16346</td>\n",
       "      <td>collaborate across all of db t practices and o...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COGREQ15586</td>\n",
       "      <td>strong technology expertise in identity and ac...</td>\n",
       "      <td>Requirement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UAEREQ12722</td>\n",
       "      <td>strong knowledge on service virtualization</td>\n",
       "      <td>Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COGSKL29155</td>\n",
       "      <td>architect scalable data processing and analyti...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHERES12551</td>\n",
       "      <td>map client organization build outstanding rela...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDRES5908</td>\n",
       "      <td>assure compliance and recommend actions to imp...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UAESKL39669</td>\n",
       "      <td>we valueknowledge of purchasing system oracle ...</td>\n",
       "      <td>Requirement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HONSSK10706</td>\n",
       "      <td>lead a global finance team in driving financia...</td>\n",
       "      <td>Responsibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COGRES1719</td>\n",
       "      <td>strong physical architecture concepts infrastr...</td>\n",
       "      <td>Skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HONREQ3632</td>\n",
       "      <td>ability to handle complex and sensitive custom...</td>\n",
       "      <td>Requirement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentence_id                                       New_Sentence  \\\n",
       "0  UAERES16346  collaborate across all of db t practices and o...   \n",
       "1  COGREQ15586  strong technology expertise in identity and ac...   \n",
       "2  UAEREQ12722         strong knowledge on service virtualization   \n",
       "3  COGSKL29155  architect scalable data processing and analyti...   \n",
       "4  PHERES12551  map client organization build outstanding rela...   \n",
       "5   INDRES5908  assure compliance and recommend actions to imp...   \n",
       "6  UAESKL39669  we valueknowledge of purchasing system oracle ...   \n",
       "7  HONSSK10706  lead a global finance team in driving financia...   \n",
       "8   COGRES1719  strong physical architecture concepts infrastr...   \n",
       "9   HONREQ3632  ability to handle complex and sensitive custom...   \n",
       "\n",
       "             Type  \n",
       "0  Responsibility  \n",
       "1     Requirement  \n",
       "2           Skill  \n",
       "3  Responsibility  \n",
       "4  Responsibility  \n",
       "5  Responsibility  \n",
       "6     Requirement  \n",
       "7  Responsibility  \n",
       "8           Skill  \n",
       "9     Requirement  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('submission.csv')\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "604b886c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Accuracy Score ->  74.70553342937039\n"
     ]
    }
   ],
   "source": [
    "print(\"MultinomialNB Accuracy Score -> \",accuracy_score(y_predict, y_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
